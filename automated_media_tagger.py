# -*- coding: utf-8 -*-
"""automated_media_tagger.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bSTNgCyhqYuD1IUNHEngLzYzE8uRdJL8
"""

from google.colab import files
import pandas as pd

uploaded = files.upload()
manual_df = pd.read_csv("manual_label.csv - Sheet1.csv")
manual_df.columns = manual_df.columns.str.strip()
print(manual_df.head())

import pandas as pd

# Load the CSV
manual_df = pd.read_csv("manual_label.csv - Sheet1 (1).csv")

# Strip any extra spaces in column names
manual_df.columns = manual_df.columns.str.strip()

# Check the first few rows
print(manual_df.head())

# Keep only relevant columns
manual_df = manual_df[['image_tag', 'manual_tags']]

# Check cleaned data
print(manual_df.head())

import pandas as pd
from google.colab import files

# Upload files manually
uploaded = files.upload()

# Load the uploaded files
manual_df = pd.read_csv("manual_label.csv - Sheet1 (1).csv")
manual_df.columns = manual_df.columns.str.strip()
manual_df = manual_df[['image_tag', 'manual_tags']]

pred_df = pd.read_csv("predictions.csv")
# Merge
merged_df = pd.merge(pred_df, manual_df, left_on='image_name', right_on='image_tag', how='left')

# Accuracy function
def tag_accuracy(predicted, manual):
    pred_set = set(predicted.split(","))
    manual_set = set(manual.split(","))
    return len(pred_set & manual_set) / len(manual_set)

# Apply
merged_df['accuracy'] = merged_df.apply(lambda row: tag_accuracy(row['predicted_tags'], row['manual_tags']), axis=1)

# View results
print(merged_df[['image_name', 'predicted_tags', 'manual_tags', 'accuracy']])

import pandas as pd

# Load CSV files
manual_df = pd.read_csv("manual_label.csv - Sheet1 (1).csv")
manual_df.columns = manual_df.columns.str.strip()
manual_df = manual_df[['image_tag', 'manual_tags']]

pred_df = pd.read_csv("predictions.csv")

# Merge manual and predicted tags
merged_df = pd.merge(
    pred_df,
    manual_df,
    left_on='image_name',
    right_on='image_tag',
    how='left'
)

# Function to calculate tag accuracy safely
def tag_accuracy(predicted, manual):
    if pd.isna(predicted) or pd.isna(manual):
        return 0.0
    pred_set = set(predicted.split(","))
    manual_set = set(manual.split(","))
    if len(manual_set) == 0:
        return 0.0
    return len(pred_set & manual_set) / len(manual_set)

# Function for precision, recall, F1
def tag_precision(predicted, manual):
    if pd.isna(predicted) or pd.isna(manual):
        return 0.0
    pred_set = set(predicted.split(","))
    manual_set = set(manual.split(","))
    if len(pred_set) == 0:
        return 0.0
    return len(pred_set & manual_set) / len(pred_set)

def tag_recall(predicted, manual):
    if pd.isna(predicted) or pd.isna(manual):
        return 0.0
    pred_set = set(predicted.split(","))
    manual_set = set(manual.split(","))
    if len(manual_set) == 0:
        return 0.0
    return len(pred_set & manual_set) / len(manual_set)

def tag_f1(predicted, manual):
    p = tag_precision(predicted, manual)
    r = tag_recall(predicted, manual)
    if p + r == 0:
        return 0.0
    return 2 * p * r / (p + r)

# Apply functions to each row
merged_df['accuracy'] = merged_df.apply(lambda row: tag_accuracy(row['predicted_tags'], row['manual_tags']), axis=1)
merged_df['precision'] = merged_df.apply(lambda row: tag_precision(row['predicted_tags'], row['manual_tags']), axis=1)
merged_df['recall'] = merged_df.apply(lambda row: tag_recall(row['predicted_tags'], row['manual_tags']), axis=1)
merged_df['f1_score'] = merged_df.apply(lambda row: tag_f1(row['predicted_tags'], row['manual_tags']), axis=1)

# Display merged results
print(merged_df[['image_name', 'predicted_tags', 'manual_tags', 'accuracy', 'precision', 'recall', 'f1_score']])

# Overall averages
print("\nOverall Metrics:")
print("Average Accuracy:", merged_df['accuracy'].mean())
print("Average Precision:", merged_df['precision'].mean())
print("Average Recall:", merged_df['recall'].mean())
print("Average F1-score:", merged_df['f1_score'].mean())

# Function to find extra and missing tags
def tag_differences(predicted, manual):
    pred_set = set(predicted.split(","))
    manual_set = set(manual.split(","))
    extra = pred_set - manual_set  # Predicted but not in manual
    missing = manual_set - pred_set  # Manual tags not predicted
    return pd.Series([list(extra), list(missing)])

# Apply to each row
merged_df[['extra_tags', 'missing_tags']] = merged_df.apply(
    lambda row: tag_differences(row['predicted_tags'], row['manual_tags']), axis=1
)

# Show the updated dataframe
print(merged_df[['image_name', 'predicted_tags', 'manual_tags', 'accuracy', 'extra_tags', 'missing_tags']])

# Import libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# -----------------------------
# Step 1: Load CSVs
# -----------------------------
manual_df = pd.read_csv("manual_label.csv - Sheet1 (1).csv")
manual_df.columns = manual_df.columns.str.strip()
manual_df = manual_df[['image_tag', 'manual_tags']]

pred_df = pd.read_csv("predictions.csv")

# -----------------------------
# Step 2: Merge data
# -----------------------------
merged_df = pd.merge(
    pred_df,
    manual_df,
    left_on='image_name',
    right_on='image_tag',
    how='left'
)

# -----------------------------
# Step 3: Define helper functions
# -----------------------------
def tag_accuracy(predicted, manual):
    """Compute accuracy (proportion of manual tags found in predicted tags)"""
    pred_set = set(predicted.lower().split(","))
    manual_set = set(manual.lower().split(","))
    return len(pred_set & manual_set) / len(manual_set)

def tag_precision(predicted, manual):
    """Precision = proportion of predicted tags that are correct"""
    pred_set = set(predicted.lower().split(","))
    manual_set = set(manual.lower().split(","))
    if len(pred_set) == 0:
        return 0
    return len(pred_set & manual_set) / len(pred_set)

def tag_recall(predicted, manual):
    """Recall = proportion of manual tags that were predicted"""
    return tag_accuracy(predicted, manual)

def tag_f1(predicted, manual):
    """F1-score"""
    p = tag_precision(predicted, manual)
    r = tag_recall(predicted, manual)
    if (p + r) == 0:
        return 0
    return 2 * p * r / (p + r)

def extra_tags(predicted, manual):
    """Tags in prediction but not in manual"""
    return list(set(predicted.lower().split(",")) - set(manual.lower().split(",")))

def missing_tags(predicted, manual):
    """Tags in manual but missing in prediction"""
    return list(set(manual.lower().split(",")) - set(predicted.lower().split(",")))

# -----------------------------
# Step 4: Apply functions
# -----------------------------
merged_df['accuracy'] = merged_df.apply(lambda row: tag_accuracy(row['predicted_tags'], row['manual_tags']), axis=1)
merged_df['precision'] = merged_df.apply(lambda row: tag_precision(row['predicted_tags'], row['manual_tags']), axis=1)
merged_df['recall'] = merged_df.apply(lambda row: tag_recall(row['predicted_tags'], row['manual_tags']), axis=1)
merged_df['f1_score'] = merged_df.apply(lambda row: tag_f1(row['predicted_tags'], row['manual_tags']), axis=1)
merged_df['extra_tags'] = merged_df.apply(lambda row: extra_tags(row['predicted_tags'], row['manual_tags']), axis=1)
merged_df['missing_tags'] = merged_df.apply(lambda row: missing_tags(row['predicted_tags'], row['manual_tags']), axis=1)

# -----------------------------
# Step 5: Display results
# -----------------------------
print(merged_df[['image_name', 'predicted_tags', 'manual_tags', 'accuracy', 'precision', 'recall', 'f1_score', 'extra_tags', 'missing_tags']])

# -----------------------------
# Step 6: Compute overall metrics
# -----------------------------
print("\nOverall Metrics:")
print("Average Accuracy:", merged_df['accuracy'].mean())
print("Average Precision:", merged_df['precision'].mean())
print("Average Recall:", merged_df['recall'].mean())
print("Average F1-score:", merged_df['f1_score'].mean())

# -----------------------------
# Step 7: Visualization
# -----------------------------
plt.figure(figsize=(10,5))
sns.barplot(x='image_name', y='accuracy', data=merged_df)
plt.title("Accuracy per Image")
plt.xticks(rotation=45)
plt.ylim(0,1)
plt.show()

# Optional: Distribution of extra tags
extra_counts = merged_df['extra_tags'].apply(len)
plt.figure(figsize=(6,4))
sns.histplot(extra_counts, bins=range(extra_counts.max()+2), kde=False)
plt.title("Number of Extra Tags per Image")
plt.xlabel("Extra Tags Count")
plt.ylabel("Number of Images")
plt.show()

!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
!pip install transformers
!pip install ftfy regex tqdm
!pip install pillow

from google.colab import files
import os

os.makedirs("images", exist_ok=True)

# Upload files manually
uploaded = files.upload()


for fname in uploaded.keys():
    os.rename(fname, os.path.join("images", fname))

# List images
image_files = [f for f in os.listdir("images/") if f.endswith(('.jpg', '.png'))]
print("Images found:", image_files)

import torch
from PIL import Image
import clip
import os

# Load the CLIP model
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

image_folder = "images/"
image_files = [f for f in os.listdir(image_folder) if f.endswith(('.jpg', '.png'))]

# Example labels you want to detect
possible_tags = ["outdoor", "indoor", "people", "food", "animal", "city", "night", "sports"]

predictions = []

for image_file in image_files:
    image_path = os.path.join(image_folder, image_file)
    image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)

    # Encode text
    text_tokens = clip.tokenize(possible_tags).to(device)

    with torch.no_grad():
        image_features = model.encode_image(image)
        text_features = model.encode_text(text_tokens)
        logits_per_image = (100.0 * image_features @ text_features.T).softmax(dim=-1)
        probs = logits_per_image.cpu().numpy()[0]

    # Select tags with probability > 0.1
    predicted_tags = [possible_tags[i] for i, p in enumerate(probs) if p > 0.1]

    predictions.append({
        "image_name": image_file,
        "predicted_tags": ",".join(predicted_tags)
    })

# Convert to DataFrame
pred_df = pd.DataFrame(predictions)
print(pred_df)

!pip install git+https://github.com/openai/CLIP.git

import clip
print("CLIP installed and imported successfully!")

import torch
from PIL import Image
import clip
import os

# Load the CLIP model
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

image_folder = "images/"
image_files = [f for f in os.listdir(image_folder) if f.endswith(('.jpg', '.png'))]

# Example labels you want to detect
possible_tags = ["outdoor", "indoor", "people", "food", "animal", "city", "night", "sports"]

predictions = []

for image_file in image_files:
    image_path = os.path.join(image_folder, image_file)
    image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)

    # Encode text
    text_tokens = clip.tokenize(possible_tags).to(device)

    with torch.no_grad():
        image_features = model.encode_image(image)
        text_features = model.encode_text(text_tokens)
        logits_per_image = (100.0 * image_features @ text_features.T).softmax(dim=-1)
        probs = logits_per_image.cpu().numpy()[0]

    # Select tags with probability > 0.1 (you can adjust threshold)
    predicted_tags = [possible_tags[i] for i, p in enumerate(probs) if p > 0.1]

    predictions.append({
        "image_name": image_file,
        "predicted_tags": ",".join(predicted_tags)
    })

# Convert to DataFrame
pred_df = pd.DataFrame(predictions)
print(pred_df)

predicted_tags = [possible_tags[i] for i, p in enumerate(probs) if p > 0.05]

# Function to calculate tag accuracy safely
def tag_accuracy(predicted, manual):
    if pd.isna(predicted):
        predicted = ""
    if pd.isna(manual):
        manual = ""
    pred_set = set(predicted.split(","))
    manual_set = set(manual.split(","))
    if len(manual_set) == 0:
        return 0.0  # avoid division by zero
    return len(pred_set & manual_set) / len(manual_set)

# Apply the function to each row
merged_df['accuracy'] = merged_df.apply(
    lambda row: tag_accuracy(row['predicted_tags'], row['manual_tags']), axis=1
)

print(merged_df[['image_name', 'predicted_tags', 'manual_tags', 'accuracy']])

import pandas as pd
import numpy as np

# Assume pred_df and manual_df are already created

# Merge predicted and manual tags
merged_df = pd.merge(
    pred_df,
    manual_df,
    left_on='image_name',
    right_on='image_tag',
    how='left'
)

# Function to calculate accuracy, extra tags, missing tags
def evaluate_tags(predicted, manual):
    if pd.isna(manual):  # Handle missing manual tags
        return 0.0, list(predicted.split(",")), []
    pred_set = set(predicted.split(","))
    manual_set = set(manual.split(","))
    accuracy = len(pred_set & manual_set) / len(manual_set)
    extra = list(pred_set - manual_set)
    missing = list(manual_set - pred_set)
    return accuracy, extra, missing

# Apply to each row
results = merged_df.apply(
    lambda row: evaluate_tags(row['predicted_tags'], row['manual_tags']), axis=1
)

# Split results into separate columns
merged_df['accuracy'], merged_df['extra_tags'], merged_df['missing_tags'] = zip(*results)

# Display the enhanced table
print(merged_df[['image_name', 'predicted_tags', 'manual_tags', 'accuracy', 'extra_tags', 'missing_tags']])

# Overall metrics
average_accuracy = merged_df['accuracy'].mean()
average_extra_tags = merged_df['extra_tags'].apply(len).mean()
average_missing_tags = merged_df['missing_tags'].apply(len).mean()

print("Overall Metrics:")
print("Average Accuracy:", average_accuracy)
print("Average Extra Tags:", average_extra_tags)
print("Average Missing Tags:", average_missing_tags)

# Install necessary packages (for Colab)
!pip install ftfy regex tqdm
!pip install git+https://github.com/openai/CLIP.git
!pip install gradio

import torch
import clip
from PIL import Image, ImageDraw, ImageFont
import pandas as pd
import os

# -----------------------------
# Load Model
# -----------------------------
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-L/14", device=device)

# -----------------------------
# Load Images
# -----------------------------
image_folder = "images/"
image_files = [f for f in os.listdir(image_folder) if f.endswith((".jpg", ".png"))]

# -----------------------------
# Define Tags
# -----------------------------
possible_tags = ["outdoor", "indoor", "people", "food", "animal", "city", "night", "sports"]

# -----------------------------
# Predict Tags
# -----------------------------
def predict_tags(image_path, threshold=0.1):
    image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)
    text_tokens = clip.tokenize(possible_tags).to(device)

    with torch.no_grad():
        image_features = model.encode_image(image)
        text_features = model.encode_text(text_tokens)
        logits = (100.0 * image_features @ text_features.T).softmax(dim=-1)
        probs = logits.cpu().numpy()[0]

    predicted = [possible_tags[i] for i, p in enumerate(probs) if p > threshold]
    return predicted

predictions = []
for img_file in image_files:
    img_path = os.path.join(image_folder, img_file)
    tags = predict_tags(img_path)
    predictions.append({"image_name": img_file, "predicted_tags": ",".join(tags)})

pred_df = pd.DataFrame(predictions)
print(pred_df)

# -----------------------------
# Merge with Manual Tags
# -----------------------------
manual_df = pd.read_csv("manual_label.csv - Sheet1 (1).csv")  # Your cleaned CSV
manual_df.columns = manual_df.columns.str.strip()
manual_df = manual_df[['image_tag', 'manual_tags']]

merged_df = pd.merge(pred_df, manual_df, left_on='image_name', right_on='image_tag', how='left')

# -----------------------------
# Evaluation Metrics
# -----------------------------
def tag_accuracy(predicted, manual):
    if pd.isna(manual):
        return 0.0
    pred_set = set(predicted.split(","))
    manual_set = set(manual.split(","))
    return len(pred_set & manual_set) / len(manual_set)

merged_df['accuracy'] = merged_df.apply(
    lambda row: tag_accuracy(row['predicted_tags'], row['manual_tags']),
    axis=1
)

# -----------------------------
# Extra & Missing Tags
# -----------------------------
def extra_missing(predicted, manual):
    if pd.isna(manual):
        return list(predicted.split(",")), []
    pred_set = set(predicted.split(","))
    manual_set = set(manual.split(","))
    extra = list(pred_set - manual_set)
    missing = list(manual_set - pred_set)
    return extra, missing

merged_df[['extra_tags', 'missing_tags']] = merged_df.apply(
    lambda row: pd.Series(extra_missing(row['predicted_tags'], row['manual_tags'])),
    axis=1
)

# -----------------------------
# Overall Metrics
# -----------------------------
print("Overall Metrics:")
print("Average Accuracy:", merged_df['accuracy'].mean())
print("Average Extra Tags:", merged_df['extra_tags'].apply(len).mean())
print("Average Missing Tags:", merged_df['missing_tags'].apply(len).mean())

# -----------------------------
# Optional: Visualize Tags on Images
# -----------------------------
def visualize_tags(image_path, tags):
    image = Image.open(image_path)
    draw = ImageDraw.Draw(image)
    font = ImageFont.load_default()
    draw.text((10, 10), ", ".join(tags), fill="red", font=font)
    image.show()

# Example: visualize first image
first_img = os.path.join(image_folder, image_files[0])
first_tags = predict_tags(first_img)
visualize_tags(first_img, first_tags)

import gradio as gr

# Function for Gradio app
def predict_image_tags(img):
    # Convert PIL Image to CLIP input
    image = preprocess(img).unsqueeze(0).to(device)
    text_tokens = clip.tokenize(possible_tags).to(device)

    with torch.no_grad():
        image_features = model.encode_image(image)
        text_features = model.encode_text(text_tokens)
        logits = (100.0 * image_features @ text_features.T).softmax(dim=-1)
        probs = logits.cpu().numpy()[0]

    # Tags with probability > 0.1
    predicted = [possible_tags[i] for i, p in enumerate(probs) if p > 0.1]
    return ", ".join(predicted)

# Launch Gradio app
gr.Interface(
    fn=predict_image_tags,
    inputs=gr.Image(type="pil"),
    outputs="text",
    title="Automated Media Tagger",
    description="Upload any image and get predicted tags using CLIP"
).launch()

import torch
from PIL import Image
import clip
import pandas as pd
import gradio as gr
import os

# Load CLIP model
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

# Example labels to detect
possible_tags = ["outdoor", "indoor", "people", "food", "animal", "city", "night", "sports"]

def predict_tags(image):
    # Preprocess and encode image
    image_input = preprocess(image).unsqueeze(0).to(device)
    text_tokens = clip.tokenize(possible_tags).to(device)

    with torch.no_grad():
        image_features = model.encode_image(image_input)
        text_features = model.encode_text(text_tokens)
        logits_per_image = (100.0 * image_features @ text_features.T).softmax(dim=-1)
        probs = logits_per_image.cpu().numpy()[0]

    # Collect tags with probability > 0.1
    predicted_tags = []
    for i, p in enumerate(probs):
        if p > 0.1:  # threshold
            predicted_tags.append(f"{possible_tags[i]} ({p:.2f})")

    return ", ".join(predicted_tags)

# Gradio interface
iface = gr.Interface(
    fn=predict_tags,
    inputs=gr.Image(type="pil"),
    outputs=gr.Textbox(label="Predicted Tags with Confidence"),
    title="Automated Media Tagger",
    description="Upload an image and get predicted tags with confidence scores using CLIP."
)

iface.launch(share=True)

import torch
from PIL import Image
import clip
import pandas as pd
import gradio as gr
import os
import zipfile

# Load CLIP
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

# Tags to detect
possible_tags = ["outdoor", "indoor", "people", "food", "animal", "city", "night", "sports"]

# Single image prediction
def predict_image(image):
    image_input = preprocess(image).unsqueeze(0).to(device)
    text_tokens = clip.tokenize(possible_tags).to(device)

    with torch.no_grad():
        image_features = model.encode_image(image_input)
        text_features = model.encode_text(text_tokens)
        logits_per_image = (100.0 * image_features @ text_features.T).softmax(dim=-1)
        probs = logits_per_image.cpu().numpy()[0]

    top_indices = probs.argsort()[::-1]
    predicted_tags = [f"{possible_tags[i]} ({probs[i]:.2f})" for i in top_indices if probs[i] > 0.1]
    return ", ".join(predicted_tags)

# Batch prediction (with uploaded images folder as ZIP)
def batch_predict(csv_file, images_zip):
    # Read CSV
    manual_df = pd.read_csv(csv_file.name)
    manual_df.columns = manual_df.columns.str.strip()
    manual_df = manual_df[['image_tag', 'manual_tags']]

    # Extract ZIP to temp folder
    extract_path = "/tmp/images"
    os.makedirs(extract_path, exist_ok=True)
    with zipfile.ZipFile(images_zip.name, 'r') as zip_ref:
        zip_ref.extractall(extract_path)

    # Get image files
    image_files = [f for f in os.listdir(extract_path) if f.endswith(('.jpg', '.png'))]

    predictions = []
    for image_file in image_files:
        image_path = os.path.join(extract_path, image_file)
        image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)
        text_tokens = clip.tokenize(possible_tags).to(device)

        with torch.no_grad():
            image_features = model.encode_image(image)
            text_features = model.encode_text(text_tokens)
            logits_per_image = (100.0 * image_features @ text_features.T).softmax(dim=-1)
            probs = logits_per_image.cpu().numpy()[0]

        predicted_tags = [possible_tags[i] for i, p in enumerate(probs) if p > 0.1]
        predictions.append({"image_name": image_file, "predicted_tags": ",".join(predicted_tags)})

    pred_df = pd.DataFrame(predictions)
    merged_df = pd.merge(pred_df, manual_df, left_on='image_name', right_on='image_tag', how='left')

    # Accuracy
    def tag_accuracy(predicted, manual):
        if pd.isna(manual):
            return 0.0
        pred_set = set(predicted.split(","))
        manual_set = set(manual.split(","))
        return len(pred_set & manual_set) / len(manual_set)

    merged_df['accuracy'] = merged_df.apply(lambda row: tag_accuracy(row['predicted_tags'], row['manual_tags']), axis=1)
    average_accuracy = merged_df['accuracy'].mean()

    return merged_df, f"Average Accuracy: {average_accuracy:.2f}"

# Gradio UI
image_interface = gr.Interface(
    fn=predict_image,
    inputs=gr.Image(type="pil"),
    outputs=gr.Textbox(label="Predicted Tags"),
    title="Single Image Media Tagger",
    description="Upload an image to detect tags automatically."
)

batch_interface = gr.Interface(
    fn=batch_predict,
    inputs=[gr.File(label="Manual CSV"), gr.File(label="Images ZIP")],
    outputs=[gr.Dataframe(label="Predictions"), gr.Textbox(label="Overall Metrics")],
    title="Batch Media Tagger",
    description="Upload a CSV and a ZIP of images to evaluate multiple images automatically."
)

demo = gr.TabbedInterface([image_interface, batch_interface], ["Single Image", "Batch Evaluation"])
demo.launch(share=True)